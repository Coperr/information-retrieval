{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32e02f0b-7db2-4aa4-897c-55c388331127",
   "metadata": {},
   "source": [
    "# inforet 2024 3\n",
    "\n",
    "### bm 25 tests and query expansion by synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e54178-39dc-4056-b037-9b486a7bdaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25 spacy Sense2Vec\n",
    "!wget https://github.com/explosion/sense2vec/releases/download/v1.0.0/s2v_reddit_2015_md.tar.gz\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import spacy\n",
    "from sense2vec import Sense2Vec\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3a30e-23d6-459c-a8e3-6d05acd4c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this turns on the autotimer, so that every cell has a timing information below\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "# stop using:\n",
    "# %unload_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bfcff9-6ea6-43f1-b638-fa581802e3fd",
   "metadata": {},
   "source": [
    "## getting the best combinations from last time and writing them into files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35e771-f5aa-4a17-9a25-46178bd8bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "origdocs = pd.read_csv('our.msmarco.docs.tsv',sep='\\t',usecols=[1,2,3])\n",
    "origdocs['title'].fillna('-', inplace=True)\n",
    "origdocs['body'].fillna('-', inplace=True)\n",
    "origdocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da4b24c-339a-4e77-99ab-e28d9f37d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(columns = ['docid', 'text'])\n",
    "docs['docid']=origdocs.docid\n",
    "docs['text']=origdocs.title+' '+origdocs.body\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a421945-a320-4b52-88be-fc9cff2b64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del origdocs # saving memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54ed965-233b-4400-9cbf-59d4613ced30",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs.to_csv('our.text.msmarco.docs.tsv',sep='\\t', columns=['docid','text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751310f9-12f4-4316-8ddc-c7f61c55eaa3",
   "metadata": {},
   "source": [
    "#### and now the pre-tokenization for bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366d052-af0b-410b-b150-5605661922b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode')\n",
    "tokenized_corpus = docs.text.progress_apply(vectorizer.build_analyzer())\n",
    "#docs['docid'].to_frame().join(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9c641-5e3b-4f37-9b22-57dc0204cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc90170d-582f-4244-ba2e-8f848d26985e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f64aa8-fbe9-45e8-b475-fda98c5ec30b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4716916-e781-41eb-b171-7a94097ed1e9",
   "metadata": {},
   "source": [
    "## reading back in just for checking the files - or for restarting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241b2b4-5108-49f8-8b96-447aa4db0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330b2b8-933c-48e9-97e8-a7958719cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a different doc, no longer distinguishing title and body\n",
    "docs = pd.read_csv('our.text.msmarco.docs.tsv',sep='\\t',usecols=[1,2]) \n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717365c-1da7-495d-a09e-c269042bd77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode')\n",
    "tokenized_corpus = docs.text.progress_apply(vectorizer.build_analyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d25cb6-4464-455d-af7a-55ed7391d0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d25f7-29b1-47b0-97c2-4558748ab27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only col 1 if you have memory problems and do BM25 only\n",
    "queries = pd.read_csv('our.msmarco.queries.tsv',sep='\\t',usecols=[1,2]) \n",
    "training_queries=queries.iloc[:500]\n",
    "testing_queries=queries.iloc[500:]\n",
    "training_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b93b6bc-9818-4e50-9287-e2c37e76a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = pd.read_csv('our.msmarco.gold.tsv',sep='\\t',usecols=[1,3,4,5])\n",
    "gold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d99aacd-2312-44ba-9350-9d15977b5632",
   "metadata": {},
   "source": [
    "# redoing the vectorization for my two best results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250a186-f76b-4862-ad59-5e31966cbc40",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "### use TfidfVectorizer, BM25Okapi, and our own BM25 function\n",
    "to measure whether there are significant differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e625902b-f97c-46ec-92fc-575d0feb55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pAt10(qid):\n",
    "    query = queries[queries.qid==qid]['query']\n",
    "    qv = vectorizer.transform(query)\n",
    "    xqv = X*qv.T\n",
    "    pred10i = np.argpartition(xqv.A.flat, -10)[-10:]\n",
    "    intersection = np.intersect1d(docs.loc[pred10i].docid,gold[gold.qid==qid].docid)\n",
    "    return len(intersection)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec81c54-7fe8-4682-aaaf-a99ef5519b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(sublinear_tf=True, strip_accents='unicode')\n",
    "X = vectorizer.fit_transform(docs.text)\n",
    "print(len(vectorizer.get_feature_names()),'features, for example',vectorizer.get_feature_names()[44444:44449])\n",
    "tfidfresults = training_queries.qid.progress_apply(pAt10)\n",
    "tfidfresults.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f3e36-f933-42d2-901a-1dc8363d714a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8699c9-b383-420c-8f68-05ab28b4ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pAt10Bm25(qid):\n",
    "    tquery = queries[queries.qid==qid]['query'].apply(vectorizer.build_analyzer())\n",
    "    doc_scores = bm25.get_scores(tquery.tolist()[0])\n",
    "    pred10i = np.argpartition(doc_scores, -10)[-10:]\n",
    "    intersection = np.intersect1d(docs.loc[pred10i].docid,gold[gold.qid==qid].docid)\n",
    "    return len(intersection)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7ed5d8-04c6-4f84-965f-4b1d595a07af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7925e-26d9-4b8f-b970-5b76f11dc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25results = training_queries.qid.progress_apply(pAt10Bm25)\n",
    "bm25results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402d379-b513-4303-af8d-37fd365f902d",
   "metadata": {},
   "source": [
    "# ðŸ”Ž manual error mining\n",
    "- let's look at where things go wrong\n",
    "\n",
    "### ðŸš§ todo:\n",
    "- what's the lowest p@10 we got\n",
    "- what's the 10 questions that got the worst score, from worst to slightly better?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562c9985-8186-4615-8982-42d86fd24031",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ca8d1d-619b-4a34-8dd2-6614ce03ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst10bm25i = ...\n",
    "worst10bm25i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4ad2d-9cad-4e24-94fb-2ae37d8135b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_queries.loc[worst10bm25i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd821669-1a60-410b-89f3-370c9c8a44a9",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "- write a function showDoc that takes qid, rank, and predicted as parameters\n",
    "    - if predicted=True, shows the predicted doc of rank rank to the query qid\n",
    "    - if predicted=False, shows the gold doc\n",
    "    - prints the first 999 characters of the texts\n",
    "- for the worst query\n",
    "    - look at the 10 best gold vs 10 best predicted \n",
    "    - hypothetize why the results are so bad for the worst query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a47c5a-32ef-4a81-b930-53dcb1371c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showDoc(qid,rank,predicted=False):\n",
    "    if predicted:\n",
    "        ...\n",
    "    else:\n",
    "        ...\n",
    "showDoc(729561,7)\n",
    "showDoc(729561,7, predicted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc959c1-a22a-4f7c-bf89-1f6b4458c343",
   "metadata": {},
   "source": [
    "### ðŸš§ todo: can we characterize these difficult cases?\n",
    "- do they have specicific problems?\n",
    "- do we know when we are doing badly?\n",
    "    - are the distances between query vector and the best documents bigger than average?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218c228e-7459-433b-82e7-779215b672c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0930c259-8ccc-4b76-93fa-428623742094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a06c1f2-25a2-4ff2-9225-47d48cf3f792",
   "metadata": {},
   "source": [
    "# ðŸš€ spacy\n",
    "\n",
    "- look at https://github.com/explosion/sense2vec/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff41e9-a1e3-43b6-bdbf-c5637ddbc681",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # or the smaller md model!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395826e9-aecf-4f81-8a9d-5f2d17bb40b3",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "- explain what's going on here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2671d9a5-a37b-43df-a921-6d5a9b6f8685",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = nlp(\"I am happy\")\n",
    "sent2 = nlp(\"I am sad\")\n",
    "sent3 = nlp(\"I am joyful\")\n",
    "sent1.similarity(sent2), sent1.similarity(sent3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d2bfd-9869-439a-81b4-c705c6c92758",
   "metadata": {},
   "source": [
    "### let's try sense2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07042087-0b00-47dd-b1e7-e0676e9ba855",
   "metadata": {},
   "source": [
    "- depending on your machine, download one of the two versions of sense2vec from https://github.com/explosion/sense2vec/blob/master/README.md\n",
    "  - s2v_reddit_2019_lg \t4 GB \tReddit comments 2019 (01-07) \tpart 1, part 2, part 3\n",
    "      - cat s2v_reddit_2019_lg.tar.gz.* > s2v_reddit_2019_lg.tar.gz\n",
    "  - s2v_reddit_2015_md \t573 MB \tReddit comments 2015 \tpart 1\n",
    "- unzip\n",
    "- try it, and understand what's going on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c224b129-f126-41f9-badc-d647f128afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2v = Sense2Vec().from_disk(\"./s2v_reddit_2019_lg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1035e78-2015-498c-92b7-9641c445327d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = \"natural language processing, machine learning, artificial intelligence\".split(',')\n",
    "seed_keys = [s2v.get_best_sense(seed.strip()) for seed in seeds]\n",
    "seed_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56314aef-a93d-4555-83b2-5ca281bc2a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar = s2v.most_similar(seed_keys, n=10)\n",
    "most_similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ddfb3-efe7-49ac-a798-301415b09968",
   "metadata": {},
   "source": [
    "### ðŸš§ todo: what is it that you couldn't do in Word2Vec?\n",
    "- just one line of answer.\n",
    "- answer: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53196513-55f7-4b21-892f-6bc7a6ca2754",
   "metadata": {},
   "source": [
    "- most_similar is very slow. check this to speed things up (optional): https://towardsdatascience.com/how-to-build-a-fast-most-similar-words-method-in-spacy-32ed104fe498\n",
    "### ðŸš§ todo:\n",
    "- try also the following functions: \n",
    "    - similarity, get_other_senses, get_freq, s2v[query]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179307dd-df67-4f8a-8fb8-8172a205e098",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1a6385-829e-4024-853f-8848004b16b7",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "- try whether expanding your query by adding similar terms to the 10 worst queries improves the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391636b4-1f60-4646-b629-52abe61db66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ab5cdc-ee45-4a5d-ba04-6c342c6b6c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e6f343-7617-4525-aeab-fd4bc9896451",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "- try misspelling a word and see whether you can fix that with sense2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922908f5-c473-4486-8674-e3618b511186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a2cd9-f443-4ff8-ad02-97832f4f0101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f6cc74a-e69b-4dcd-849f-7b3c7293bd08",
   "metadata": {},
   "source": [
    "### ðŸš§ todo:\n",
    "- try embeddings for a few queries (all would take to long except if you have a GPU)\n",
    "    - are the gold top 10 similar to the query itself?\n",
    "    - check whether the gold top 10 answers for our most difficult question are really closer to the question than the currently predicted top10\n",
    "         - how to get every doc as a vector: \n",
    "             - https://spacy.io/api/doc#vector \"A real-valued meaning representation. Defaults to an average of the token vectors.\"\n",
    "        - every doc has a similarity function taking another doc as argument: \n",
    "            - https://spacy.io/api/doc#similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc0ab9b-ff88-41e9-96c6-c21969303775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f249f2d-6449-4951-9514-e7116b861cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary but if you want to include your big s2v file\n",
    "# combining spacy and sense2vec:\n",
    "nlp = spacy.load(\"en_core_web_sm\") # or whichever you downloaded\n",
    "s2v = nlp.add_pipe(\"sense2vec\")\n",
    "s2v.from_disk(\"./s2v_reddit_2015_md\") # or whichever you downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a47821-5f24-4e14-829d-cc7a0f448866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
