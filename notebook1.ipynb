{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inforet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we will work with the UN General Debate dataset. The corpus consists of 7,507 speeches held at the annual sessions of the United Nations General Assembly from 1970 to 2016. It was created in 2017 by Mikhaylov, Baturo, and Dasandi at Harvard ‚Äúfor understanding and measuring state preferences in world politics.‚Äù Each of the almost 200 countries in the United Nations has the opportunity to present its views on global topics such international conflicts, terrorism, or climate change at the annual General Debate.\n",
    "Work on this data is proposed in the book \n",
    "\n",
    "- https://github.com/blueprints-for-text-analytics-python/blueprints-text\n",
    "- from here, but it's easier to use the version on my server. \n",
    "  - https://github.com/blueprints-for-text-analytics-python/blueprints-text/blob/master/data/un-general-debates/un-general-debates-blueprint.csv.gz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## downloading some toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the file un-general-debates-blueprint.csv is present\n",
    "# if not, download it from the web and unzip it\n",
    "import os\n",
    "\n",
    "file_name = 'un-general-debates-blueprint.csv'\n",
    "gz_file = file_name + '.gz'\n",
    "url = 'https://gerdes.fr/saclay/inforet/' + gz_file\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    print('File already present')\n",
    "else:\n",
    "    print('Downloading the file...')\n",
    "    os.system(f'curl -o {gz_file} {url}')\n",
    "    os.system(f'gunzip {gz_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t\n",
    "if you have a problem with the above code, \n",
    "you can also simply get the zip, unzip and put it manuaylly next to your notbook:\n",
    "\n",
    "https://gerdes.fr/saclay/informationRetrieval/un-general-debates-blueprint.csv.gz\n",
    "\n",
    "or try using wget:\n",
    "```\n",
    "!wget https://gerdes.fr/saclay/informationRetrieval/un-general-debates-blueprint.csv.gz\n",
    "import gzip, shutil\n",
    "with open('un-general-debates-blueprint.csv.gz', 'rb') as f_in:\n",
    "    with gzip.open('un-general-debates-blueprint.csv', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "```\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this turns on the autotimer, so that every cell has a timing information below\n",
    "try:\n",
    "    %load_ext autotime\n",
    "except:\n",
    "    !pip install ipython-autotime\n",
    "    %load_ext autotime\n",
    "# to stop using autotime, run the following command\n",
    "# %unload_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"un-general-debates-blueprint.csv\")\n",
    "df.sample(22) #, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get to know the data (and Pandas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns, df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo: \n",
    "- explain \n",
    "\t- why only two rows?\n",
    "\t- the strange row above and the values you find. Look into the data!\n",
    "\n",
    "answers: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')\n",
    "# check the total memory usage compared to the original file size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding length columns, describing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_chars'] = df['text'].str.len()\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo: estimate the number of words\n",
    "\n",
    "- what's the average word size in English? (Remember HoNLP, that class before the vacation?)\n",
    "- what's the mean, min, and max of estimated wordsize?\n",
    "- suppose that a page 11pt has on average 600 words, what are the values in number of pages?\n",
    "- suppose that on average, an English speaker pronounces 150 words per minute, what are the values for the duration of the speeches?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'longest, shortest, and average speech in words: {df[\"nb_chars\"]...\n",
    "print(f'longest, shortest, and average speech in pages: {df[\"nb_chars\"]...\n",
    "print(f'longest, shortest, and average speech in minutes: {df[\"nb_chars\"]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### üöß todo: add a wordlength column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # üöß todo: explain why this fails\n",
    "# df['nb_words'] = df['text'].str.split().len()\n",
    "# # üöß todo: explain why this fails\n",
    "# df['nb_words'] = df['text'].str.split().apply(len)\n",
    "\n",
    "# üöß todo: find a way of getting this column\n",
    "\n",
    "\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "16424.0/2611.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo: check the results\n",
    "\n",
    "- how was our estimate of word length compared to reality?\n",
    "- if your minumum wordlength is now 0 or 1, explain by checking the file.\n",
    "- the simple tokenization by splitting gives in average longer or shorter words than a more linguistically motivated tokenization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['country', 'country_name', 'speaker', 'position']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß TODO: \n",
    "- why does the describe() function works differently now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN ‚â† NA\n",
    "NaN means 0/0. NaN stands for Not a Number\n",
    "\n",
    "NA is generally interpreted as a missing value and has various forms - NA_integer_, NA_real_, etc.\n",
    "\n",
    "https://stats.stackexchange.com/questions/5686/what-is-the-difference-between-nan-and-na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['position'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'speaker': 'unknown', 'position': 'unknown'}, inplace=True)\n",
    "df[df['position'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# categorical values vs numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['speaker'].str.contains('Bush')]['speaker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_words'].plot(kind='box', vert=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nb_words'].plot(kind='hist', bins=30) # , figsize=(8,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel density estimation\n",
    "\n",
    "https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
    "\n",
    "if error: \"FutureWarning: `distplot` is a deprecated function\"\n",
    "\n",
    "update scipy: `pip3 install --upgrade scipy `\n",
    "\n",
    "if it persists\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if you got warnings!!!\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8, 2))\n",
    "sns.histplot(df['nb_words'], bins=30, kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seaborn docs?\n",
    "https://seaborn.pydata.org/index.html  \n",
    "https://seaborn.pydata.org/generated/seaborn.distplot.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from where?\n",
    "\n",
    "catplot shows the relationship between a numerical and one or more categorical variables.\n",
    "https://seaborn.pydata.org/generated/seaborn.catplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df, x=\"country\", y=\"nb_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to build a selection:\n",
    "df['country'].isin(['USA', 'FRA', 'GBR', 'CHN', 'RUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the selection\n",
    "where = df['country'].isin(['USA', 'FRA', 'GBR', 'CHN', 'RUS'])\n",
    "sns.catplot(data=df[where], x=\"country\", y=\"nb_words\", kind='box')\n",
    "sns.catplot(data=df[where], x=\"country\", y=\"nb_words\", kind='violin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## significant differences?\n",
    "\n",
    "Student test? Anova ?\n",
    "\n",
    "if the boxes (marking the quartiles) don't overlap each other and the sample size is at least 10, then the two groups being compared should have different medians at the 5% level: https://stats.stackexchange.com/questions/262495/reading-box-and-whisker-plots-possible-to-glean-significant-differences-between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(data=df[where], x=\"country\", y=\"nb_words\", kind='box', notch= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time?\n",
    "\n",
    "size() returns the number of rows per group  \n",
    "Why number of countries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('year').size().plot(title=\"Number of Countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when more people want to speak, ...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('year').agg({'nb_words': 'mean'}).plot(title=\"Avg. Speech Length\", ylim=(0,5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where = df['country'].isin(['USA', 'FRA', 'GBR', 'CHN', 'RUS', 'FRG', 'DEU'])\n",
    "sns.catplot(data=df[where], x=\"country\", y=\"nb_words\", kind='box', notch= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöß todo: When speaking English, do Germans use longer words?\n",
    "\n",
    "- Compare to British natives, US natives, and French speakers. \n",
    "- Is the result significant?\n",
    "- How do you explain this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöß todo:\n",
    "df['avg_wordsize'] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöß todo:\n",
    "where = df['country'].isin..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo:\n",
    "answer: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's Zipf it!\n",
    "## skim through this section if you have followed Hands-on NLP!\n",
    "but execute the code so that we have the freq_df and start again at word clouds\n",
    "### Let's first flatten the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = [word for speech in df['text'].dropna() for word in re.findall(r'\\b\\w+\\b', speech.lower())]\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Wait... what?! What? WHAT?! You're telling me that 99.9% of statistics‚Äîincluding this one‚Äîare made up?! Made up, I say! Completely, absolutely, 100% made up!\"\n",
    "counter = Counter(re.findall(r'\\b\\w+\\b', text.lower()))\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common words of English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(all_words)\n",
    "counter.most_common(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for even bigger databases, it might be advisable to do the computation iteratively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "df['text'].dropna().apply(lambda text: counter.update(re.findall(r'\\b\\w+\\b', text.lower())))\n",
    "counter.most_common(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "freq_df.sort_values('freq',  inplace=True, ascending=False)\n",
    "freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.head(22).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.head(2222).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_df.head(2222).plot(loglog=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "futher reading:  \n",
    "https://en.wikipedia.org/wiki/Zipf's_law  \n",
    "https://stats.stackexchange.com/questions/6780/how-to-calculate-zipfs-law-coefficient-from-a-set-of-top-frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word cloud\n",
    "\n",
    "http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html#wordcloud.WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.query(\"year==2015 and country=='USA'\")['text'].values[0]\n",
    "wc = WordCloud(max_words=100)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1, 2, figsize=(20, 4))\n",
    "\n",
    "text = df.query(\"country=='USA'\")['text'].values[0]\n",
    "wc = WordCloud(max_words=100)\n",
    "wc.generate(text)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "text = df.query(\"country=='RUS'\")['text'].values[0]\n",
    "wc = WordCloud(max_words=100)\n",
    "wc.generate(text)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(max_words=100, stopwords=freq_df.head(50).index)\n",
    "wc.generate(text)\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the `generate_from_frequencies` function allows to generate without stopwords directly from a Counter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate_from_frequencies(counter)\n",
    "plt.title('from counter')\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "We want to build an inverted index:\n",
    "- make a df such that for every type, we have a 1 if the document contains the type, 0 if not.\n",
    "- for every type, give a list of document ids\n",
    "\n",
    "# üöß todo:\n",
    "- how many types do we have?\n",
    "- how many documents do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...,'types')\n",
    "print(...,'documents')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(freq_df.index[66:77])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[33:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((11, 3))\n",
    "A.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will first try the na√Øve way, to find out that this easily gets too slow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,t in enumerate(freq_df.index[66:77]):\n",
    "    for j, text in enumerate(df['text'][33:36]):\n",
    "        # Tokenize text using regex\n",
    "        tokens = set(re.findall(r'\\b\\w+\\b', text.lower()))  # Use set for faster lookup\n",
    "        if t in tokens:\n",
    "            A[i, j] = 1  # Mark presence of token in text\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((100, 7507)) # understand this: 100 most frequent words, 7507 speeches\n",
    "for i,t in tqdm(enumerate(freq_df.index[:100])):\n",
    "    for j, text in enumerate(df['text'][33:100]): # play with the range to see how slow your machine is\n",
    "        tokens = set(re.findall(r'\\b\\w+\\b', text.lower())) \n",
    "        if t in tokens:\n",
    "               A[i,j] =1\n",
    "# can you do that loop more efficiently? This is not an obligatory task.\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöß todo:\n",
    "\n",
    "What would be the size of the complete table?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöß todo:\n",
    "A = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üöß todo:\n",
    "\n",
    "How long will it take to fill the complete table?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöß todo:\n",
    "# i take 9 seconds per 100, should be about linear\n",
    "...,'seconds',...,'minutes', ...,'hours'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redoing the same thing with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df[33:36].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=freq_df.index[66:77], binary=True, min_df=1, lowercase=False)\n",
    "# understand the options: \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "X = vectorizer.fit_transform(df[33:36].text)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it pretty:\n",
    "d = {c:X.toarray()[i] for i,c in enumerate(df[33:36].index)}\n",
    "df_cv = pd.DataFrame.from_dict(d,  orient='index',columns=freq_df.index[66:77])\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying the complete set of documents with the complete vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=freq_df.index, binary=True, min_df=1, lowercase=False)\n",
    "X = vectorizer.fit_transform(df['text'].dropna())\n",
    "print(len(vectorizer.get_feature_names_out()))\n",
    "print(vectorizer.get_feature_names_out()[:11])\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- wow! comparably fast!\n",
    "#### üöß todo:\n",
    "- can you get the vector of \"the\"? is there a speech that doesn't use it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo: some visualizations of the vectorization\n",
    "\n",
    "- make 2D scatterplots of the vectorization using PCA and t-SNE.\n",
    "- use the years as hue\n",
    "- explain why this looks so different\n",
    "- hard: choose a cluster that looks mainly stemming from earlier texts, another stemming from recent texts, and find a few examples of terms that makes them different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42, n_iter=1000)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze two clusters of the PCA plot: top right and bottom left:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define clusters based on PCA components\n",
    "cluster_1 = pca_df[pca_df[\"PC1\"] > 0.8].index\n",
    "cluster_2 = pca_df[(pca_df[\"PC1\"] < -0.2) & (pca_df[\"PC2\"] > 0.8)].index\n",
    "\n",
    "# Extract corresponding texts\n",
    "...\n",
    "diff_df = diff_df.sort_values(by=[ \"Cluster 2 (PC1 < -0.2, PC2 > 0.8)\", \"Cluster 1 (PC1 > 0.8)\"], ascending=False)\n",
    "# Show distinctive words\n",
    "diff_df.head(10)\n",
    "# of both clusters (since we have a binary vectorizer, we only get present and absent words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# another big vocabulary:\n",
    "- we could grab a pageview file here https://dumps.wikimedia.org/other/pageviews/2022/2022-01/ and  produce a list of potential terms from it\n",
    "- it's easier to use wikidata, and we concentrate on people:\n",
    "\n",
    "here is code that grabs it and produces a file of person names. this API is unstable, so i propose to download directly the result on my website, see code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can skip this cell if you are only interested in the result, see next cell\n",
    "\n",
    "def fetch_wikidata_humans(limit=10000, offset=0):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "    query = f\"\"\"\n",
    "    SELECT ?human ?humanLabel WHERE {{\n",
    "      ?human wdt:P31 wd:Q5.  # Humans (Q5)\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    LIMIT {limit}\n",
    "    OFFSET {offset}\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results\n",
    "\n",
    "# Fetch the first batch\n",
    "humans_data = []\n",
    "offset = 0\n",
    "batch_size = 5000  # Fetch this batch size at a time\n",
    "\n",
    "while True:\n",
    "    print(f\"Fetching humans from offset {offset}\")\n",
    "    results = fetch_wikidata_humans(limit=batch_size, offset=offset)\n",
    "    if \"results\" in results and \"bindings\" in results[\"results\"]:\n",
    "        batch = results[\"results\"][\"bindings\"]\n",
    "        if not batch:\n",
    "            break  # Stop if no more results\n",
    "\n",
    "        for result in batch:\n",
    "            humans_data.append({\n",
    "                \"Wikidata ID\": result[\"human\"][\"value\"].split(\"/\")[-1],\n",
    "                \"Name\": result[\"humanLabel\"][\"value\"]\n",
    "            })\n",
    "        offset += batch_size  # Move to the next batch\n",
    "    else:\n",
    "        break  # Stop if no valid response\n",
    "\n",
    "# Convert to DataFrame\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(humans_data)\n",
    "\n",
    "# write the Name column to a file\n",
    "df['Name'].to_csv('wikidata_names.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'wikidata_names.txt'\n",
    "zip_file = file_name + '.zip'\n",
    "url = 'https://gerdes.fr/saclay/inforet/' + zip_file\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    print('File already present')\n",
    "else:\n",
    "    print('Downloading the file...')\n",
    "    os.system(f'curl -o {zip_file} {url}')\n",
    "    os.system(f'unzip {zip_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file back into a simple list, one item per line\n",
    "with open('wikidata_names.txt') as f:\n",
    "\tnames = set(f.read().splitlines())\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=names, binary=True, min_df=1, lowercase=False, ngram_range=(1,4))\n",
    "X = vectorizer.fit_transform(df.text.dropna())\n",
    "print(len(vectorizer.get_feature_names_out()))\n",
    "print(vectorizer.get_feature_names_out()[:11])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üöß todo: \n",
    "- find the most frequently cited names\n",
    "- analyze who cites\n",
    "- analyze the length of the cited names in tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check this: https://en.wikipedia.org/wiki/Kofi_Annan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "complete the # üöß todo:\n",
    "\n",
    "and\n",
    "## find the most frequently encountered person entity\n",
    "- in number of speeches\n",
    "- in number of occurrences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before submitting, check:\n",
    "- I have not imported any other modules\n",
    "- I have put explanations between the lines of code (either inline or in separate cells)\n",
    "- My notebook runs all the way through when I hit\n",
    "  1. the ‚Üª button and then\n",
    "  2. the ‚è©Ô∏é button (remove or comment out cells that are too slow and not needed).\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (envgen)",
   "language": "python",
   "name": "envgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
